{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from utils.create_hash import create_word_to_int, create_int_to_word\n",
    "import re\n",
    "import numpy\n",
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (0):\n",
    "    rf = open(\"./data/hp0.txt\", \"r\", encoding=\"utf8\")\n",
    "    wf = open(\"./data/hp1.txt\", \"w\", encoding=\"utf8\")\n",
    "    for line in rf.readlines():\n",
    "        if (re.match(\"Page | . Harry Potter and the Philosophers Stone - J.K. Rowling\", line) == None and line != \"\\n\"):\n",
    "            wf.write(line)\n",
    "    rf.close()\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "rf = open(\"./data/hp1.txt\", \"r\", encoding=\"utf8\")\n",
    "doc = nlp(rf.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_int = create_word_to_int(doc)\n",
    "int_to_word = create_int_to_word(word_to_int)\n",
    "print(\"word_to_int and int_to_word create done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_to_int[\"THE\"])\n",
    "print(int_to_word[6692])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ngram import ngram\n",
    "\n",
    "word_ngram = ngram(doc, 7, word_to_int)\n",
    "print(\"create n gram done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_ngram[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_ngram = embed(list(zip(*word_ngram))[0])\n",
    "labels = list(zip(*word_ngram))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(word_ngram))\n",
    "print(embedded_ngram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(512,))\n",
    "num_classes = len(word_to_int)\n",
    "x = layers.Dense(3000, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(embedded_ngram.numpy(), numpy.array(labels),\n",
    "          batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 6675)\nThe\n"
     ]
    }
   ],
   "source": [
    "embedded = embed(['One day in July,'])\n",
    "outputboi = model.predict(embedded.numpy()) # 1 * 6000\n",
    "print(outputboi.shape)\n",
    "outputboi = tf.math.argmax(outputboi, axis=1)\n",
    "print(int_to_word_loaded[int(outputboi.numpy()[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('xd/xd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_int_loaded = pickle.load(open(\"word2int.p\", \"rb\"))\n",
    "int_to_word_loaded = create_int_to_word(word_to_int_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}